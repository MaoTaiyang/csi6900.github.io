{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaoTaiyang/csi6900.github.io/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdVYKHAlThrO",
        "outputId": "24254ba6-c184-4256-c106-942732aa44cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,105 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,436 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,606 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,665 kB]\n",
            "Fetched 15.2 MB in 6s (2,562 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "libopencv-dev is already the newest version (4.5.4+dfsg-9ubuntu4+jammy0).\n",
            "The following additional packages will be installed:\n",
            "  python3-numpy\n",
            "Suggested packages:\n",
            "  python-numpy-doc python3-pytest\n",
            "The following NEW packages will be installed:\n",
            "  python3-numpy python3-opencv\n",
            "0 upgraded, 2 newly installed, 0 to remove and 51 not upgraded.\n",
            "Need to get 5,272 kB of archives.\n",
            "After this operation, 27.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-numpy amd64 1:1.21.5-1ubuntu22.04.1 [3,467 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-opencv amd64 4.5.4+dfsg-9ubuntu4+jammy0 [1,805 kB]\n",
            "Fetched 5,272 kB in 1s (3,572 kB/s)\n",
            "Selecting previously unselected package python3-numpy.\n",
            "(Reading database ... 123623 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.21.5-1ubuntu22.04.1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Selecting previously unselected package python3-opencv:amd64.\n",
            "Preparing to unpack .../python3-opencv_4.5.4+dfsg-9ubuntu4+jammy0_amd64.deb ...\n",
            "Unpacking python3-opencv:amd64 (4.5.4+dfsg-9ubuntu4+jammy0) ...\n",
            "Setting up python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Setting up python3-opencv:amd64 (4.5.4+dfsg-9ubuntu4+jammy0) ...\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y cmake libopencv-dev python3-opencv\n",
        "!pip install opencv-python-headless numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "C5eUMolaW15o",
        "outputId": "989a37d8-648d-4853-fe88-3004913cfb77"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85e6a0bd-d21e-43a3-9d90-124f3a83abd4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85e6a0bd-d21e-43a3-9d90-124f3a83abd4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 00f8e9a1c8862eefc073342f333391f5.mp4 to 00f8e9a1c8862eefc073342f333391f5.mp4\n",
            "上传的文件名: 00f8e9a1c8862eefc073342f333391f5.mp4\n",
            "视频路径: /content/00f8e9a1c8862eefc073342f333391f5.mp4\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 上传视频文件\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 确认视频文件路径\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"上传的文件名: {filename}\")\n",
        "\n",
        "video_path = f\"/content/{list(uploaded.keys())[0]}\"  # 获取上传文件路径\n",
        "print(f\"视频路径: {video_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRDeqC7aYXQj",
        "outputId": "d4eaaa73-0c06-4ea7-bf00-c484c628e129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00f8e9a1c8862eefc073342f333391f5.mp4  pose_iter_584000.caffemodel.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNPoN16QaZ11",
        "outputId": "528f6178-2b95-4e6d-f3e0-419878e385a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW8zyHEqTroR",
        "outputId": "298812b8-ea0d-4dbc-d05a-a982bf022645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'openpose'...\n",
            "remote: Enumerating objects: 16156, done.\u001b[K\n",
            "remote: Total 16156 (delta 0), reused 0 (delta 0), pack-reused 16156 (from 1)\u001b[K\n",
            "Receiving objects: 100% (16156/16156), 84.46 MiB | 24.38 MiB/s, done.\n",
            "Resolving deltas: 100% (11324/11324), done.\n",
            "/content/openpose\n",
            "Submodule '3rdparty/caffe' (https://github.com/CMU-Perceptual-Computing-Lab/caffe.git) registered for path '3rdparty/caffe'\n",
            "Submodule '3rdparty/pybind11' (https://github.com/pybind/pybind11.git) registered for path '3rdparty/pybind11'\n",
            "Cloning into '/content/openpose/3rdparty/caffe'...\n",
            "Cloning into '/content/openpose/3rdparty/pybind11'...\n",
            "Submodule path '3rdparty/caffe': checked out 'b5ede488952e40861e84e51a9f9fd8fe2395cc8a'\n",
            "Submodule path '3rdparty/pybind11': checked out '085a29436a8c472caaaf7157aa644b571079bcaa'\n",
            "Submodule 'tools/clang' (https://github.com/wjakob/clang-cindex-python3) registered for path '3rdparty/pybind11/tools/clang'\n",
            "Cloning into '/content/openpose/3rdparty/pybind11/tools/clang'...\n",
            "Submodule path '3rdparty/pybind11/tools/clang': checked out '6a00cbc4a9b8e68b71caf7f774b3f9c753ae84d5'\n",
            "--2024-11-02 02:09:04--  http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/body_25/pose_iter_584000.caffemodel\n",
            "Resolving posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)... 128.2.220.57\n",
            "Connecting to posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)|128.2.220.57|:80... failed: No route to host.\n",
            "--2024-11-02 02:09:04--  https://raw.githubusercontent.com/CMU-Perceptual-Computing-Lab/openpose/master/models/pose/body_25/pose_deploy.prototxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42330 (41K) [text/plain]\n",
            "Saving to: ‘models/pose/body_25/pose_deploy.prototxt.1’\n",
            "\n",
            "pose_deploy.prototx 100%[===================>]  41.34K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-11-02 02:09:04 (2.36 MB/s) - ‘models/pose/body_25/pose_deploy.prototxt.1’ saved [42330/42330]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CMU-Perceptual-Computing-Lab/openpose.git\n",
        "%cd openpose\n",
        "!git submodule update --init --recursive\n",
        "\n",
        "# 下载模型文件\n",
        "!mkdir -p models/pose/body_25\n",
        "!wget -P models/pose/body_25/ http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/body_25/pose_iter_584000.caffemodel\n",
        "!wget -P models/pose/body_25/ https://raw.githubusercontent.com/CMU-Perceptual-Computing-Lab/openpose/master/models/pose/body_25/pose_deploy.prototxt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzrxwIhpT-GO",
        "outputId": "a6eb0077-9c1f-4c1b-cd0d-027a0212fb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.5.5.64\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless==4.5.5.64) (1.26.4)\n",
            "Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.10.0.84\n",
            "    Uninstalling opencv-python-headless-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-headless-4.10.0.84\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.5.5.64 which is incompatible.\n",
            "albumentations 1.4.20 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.5.5.64 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed opencv-python-headless-4.5.5.64\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless==4.5.5.64  # 安装特定版本的OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES8e7jWvUC3B",
        "outputId": "0410af1a-48ae-4d18-c25f-c7f42edd8e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-02 02:09:13--  http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/body_25/pose_iter_584000.caffemodel\n",
            "Resolving posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)... 128.2.220.57\n",
            "Connecting to posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)|128.2.220.57|:80... failed: No route to host.\n",
            "--2024-11-02 02:09:13--  https://raw.githubusercontent.com/CMU-Perceptual-Computing-Lab/openpose/master/models/pose/body_25/pose_deploy.prototxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42330 (41K) [text/plain]\n",
            "Saving to: ‘/content/openpose/models/pose/body_25/pose_deploy.prototxt.2’\n",
            "\n",
            "pose_deploy.prototx 100%[===================>]  41.34K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-11-02 02:09:14 (2.65 MB/s) - ‘/content/openpose/models/pose/body_25/pose_deploy.prototxt.2’ saved [42330/42330]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 创建目录\n",
        "!mkdir -p /content/openpose/models/pose/body_25\n",
        "\n",
        "# 下载模型文件\n",
        "!wget -P /content/openpose/models/pose/body_25/ http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/body_25/pose_iter_584000.caffemodel\n",
        "!wget -P /content/openpose/models/pose/body_25/ https://raw.githubusercontent.com/CMU-Perceptual-Computing-Lab/openpose/master/models/pose/body_25/pose_deploy.prototxt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8S73u1dUP8t",
        "outputId": "d74bb894-8112-4183-ba07-7daa82db7053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/pose_iter_584000.caffemodel.zip\n",
            "  inflating: /content/openpose/models/pose/body_25/pose_iter_584000.caffemodel  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/pose_iter_584000.caffemodel.zip -d /content/openpose/models/pose/body_25/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz6N-I5ZVBaj",
        "outputId": "5857693d-eb5c-472e-d7db-a8edab0804dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型文件存在: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"模型文件存在:\", os.path.exists(\"/content/openpose/models/pose/body_25/pose_iter_584000.caffemodel\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XhmPuIgVFfL",
        "outputId": "dda38dee-40d0-42db-a8d9-79ba6ba56362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "0Gpd0Z8TVKh4",
        "outputId": "98a6673d-966f-4332-d7e6-eba5736604ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "视频文件成功打开\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0d09373ec4c3>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0minput_blob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m368\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m368\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswapRB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_blob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# 解析关键点\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# OpenPose 模型路径\n",
        "proto_file = \"/content/openpose/models/pose/body_25/pose_deploy.prototxt\"\n",
        "weights_file = \"/content/openpose/models/pose/body_25/pose_iter_584000.caffemodel\"\n",
        "net = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n",
        "\n",
        "# 读取视频\n",
        "video_path = \"/content/00f8e9a1c8862eefc073342f333391f5.mp4\"  # 替换为你上传的视频路径\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    print(\"无法打开视频文件，请检查路径和文件格式\")\n",
        "else:\n",
        "    print(\"视频文件成功打开\")\n",
        "\n",
        "# 获取视频的宽、高、帧率\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# 定义输出视频\n",
        "out = cv2.VideoWriter('/content/output_video.mp4', cv2.VideoWriter_fourcc(*'MJPG'), fps, (frame_width, frame_height))\n",
        "\n",
        "\n",
        "\n",
        "# 初始化轨迹列表\n",
        "keypoint_tracks = [[] for _ in range(25)]  # Body_25 关键点\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"视频结束\")\n",
        "        break\n",
        "\n",
        "    out.write(frame)\n",
        "    frame_count += 1\n",
        "    if frame_count % 100 ==0:\n",
        "      print(f\"处理并写入第 {frame_count} 帧\")\n",
        "\n",
        "    # 转换为Blob并进行前向传播\n",
        "    input_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (368, 368), (0, 0, 0), swapRB=False, crop=False)\n",
        "    net.setInput(input_blob)\n",
        "    output = net.forward()\n",
        "\n",
        "    # 解析关键点\n",
        "    points = []\n",
        "    for i in range(25):\n",
        "        heat_map = output[0, i, :, :]\n",
        "        _, conf, _, point = cv2.minMaxLoc(heat_map)\n",
        "        x = int((frame.shape[1] * point[0]) / output.shape[3])\n",
        "        y = int((frame.shape[0] * point[1]) / output.shape[2])\n",
        "\n",
        "        if conf > 0.1:  # 置信度阈值\n",
        "            points.append((x, y))\n",
        "            keypoint_tracks[i].append((x, y))  # 添加轨迹\n",
        "            cv2.circle(frame, (x, y), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
        "        else:\n",
        "            points.append(None)\n",
        "\n",
        "    # 在视频中绘制轨迹\n",
        "    for track in keypoint_tracks:\n",
        "        for j in range(1, len(track)):\n",
        "            if track[j - 1] is not None and track[j] is not None:\n",
        "                cv2.line(frame, track[j - 1], track[j], (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "    if frame_count % 100 ==0:\n",
        "      print(f\"处理完成的总帧数: {frame_count}\")\n",
        "\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "\n",
        "\n",
        "print(\"视频处理完成！\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "if tf.test.is_gpu_available():\n",
        "    print(\"TensorFlow will run on GPU\")\n",
        "else:\n",
        "    print(\"TensorFlow cannot find GPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0eu5bIafrRR",
        "outputId": "5b0fb689-529a-404c-d028-f3f0127f4dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-9dae7bc3eef1>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n",
            "TensorFlow cannot find GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "MjK0w4dpmwh9",
        "outputId": "f07101c6-d4d8-4046-fd98-84ff7e899eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n",
            "340\n",
            "350\n",
            "360\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.5.5) /io/opencv/modules/highgui/src/window.cpp:1262: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9823ed0286ff>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"视频处理完成并保存为 'output_video.mp4'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /io/opencv/modules/highgui/src/window.cpp:1262: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# OpenPose 模型文件路径\n",
        "proto_file = \"/content/openpose/models/pose/body_25/pose_deploy.prototxt\"\n",
        "weights_file = \"/content/openpose/models/pose/body_25/pose_iter_584000.caffemodel\"\n",
        "net = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "print(1)\n",
        "# 读取视频\n",
        "video_path = \"/content/00f8e9a1c8862eefc073342f333391f5.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "print(2)\n",
        "# 视频输出设置\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "out = cv2.VideoWriter('/content/output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "# 定义 BODY_25 连接线\n",
        "pairs = [[1, 8], [1, 2], [1, 5], [2, 3], [3, 4], [5, 6], [6, 7], [8, 9], [9, 10], [10, 11], [11, 22],\n",
        "         [22, 23], [11, 24], [8, 12], [12, 13], [13, 14], [14, 19], [19, 20], [14, 21], [0, 15],\n",
        "         [0, 16], [15, 17], [16, 18]]\n",
        "print(3)\n",
        "j=1\n",
        "# 处理视频帧\n",
        "while cap.isOpened():\n",
        "    j = j + 1\n",
        "    if j%10 == 0:\n",
        "      print(j)\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "\n",
        "    # 转换为Blob格式\n",
        "    input_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (368, 368), (0, 0, 0), swapRB=False, crop=False)\n",
        "    net.setInput(input_blob)\n",
        "    output = net.forward()\n",
        "\n",
        "    # 解析关键点\n",
        "    points = []\n",
        "    for i in range(25):\n",
        "        heat_map = output[0, i, :, :]\n",
        "        _, conf, _, point = cv2.minMaxLoc(heat_map)\n",
        "        x = int((point[0] / output.shape[3]) * frame.shape[1])\n",
        "        y = int((point[1] / output.shape[2]) * frame.shape[0])\n",
        "        points.append((x, y) if conf > 0.1 else None)\n",
        "        if conf > 0.1:\n",
        "            cv2.circle(frame, (x, y), 3, (0, 255, 255), -1, cv2.LINE_AA)\n",
        "\n",
        "    # 绘制骨架连接线\n",
        "    for pair in pairs:\n",
        "        partA = pair[0]\n",
        "        partB = pair[1]\n",
        "        if points[partA] and points[partB]:\n",
        "            cv2.line(frame, points[partA], points[partB], (0, 255, 0), 2)\n",
        "\n",
        "    # 写入输出视频\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(\"视频处理完成并保存为 'output_video.mp4'\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# OpenPose 模型文件路径\n",
        "proto_file = \"/content/openpose/models/pose/body_25/pose_deploy.prototxt\"\n",
        "weights_file = \"/content/openpose/models/pose/body_25/pose_iter_584000.caffemodel\"\n",
        "net = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "print(1)\n",
        "# 读取视频\n",
        "video_path = \"/content/00f8e9a1c8862eefc073342f333391f5.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "print(2)\n",
        "# 视频输出设置\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "out = cv2.VideoWriter('/content/output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "# 定义 BODY_25 连接线\n",
        "pairs = [[1, 8], [1, 2], [1, 5], [2, 3], [3, 4], [5, 6], [6, 7], [8, 9], [9, 10], [10, 11], [11, 22],\n",
        "         [22, 23], [11, 24], [8, 12], [12, 13], [13, 14], [14, 19], [19, 20], [14, 21], [0, 15],\n",
        "         [0, 16], [15, 17], [16, 18]]\n",
        "print(3)\n",
        "j=1\n",
        "# 处理视频帧\n",
        "all_points = []#存储所有节点的列表\n",
        "while cap.isOpened():\n",
        "    j = j + 1\n",
        "    if j%100 == 0:\n",
        "      print(j)\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    # 创建一个空白背景\n",
        "    blank_frame = np.zeros_like(frame)\n",
        "\n",
        "    # 转换为Blob格式\n",
        "    input_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (368, 368), (0, 0, 0), swapRB=False, crop=False)\n",
        "    net.setInput(input_blob)\n",
        "    output = net.forward()\n",
        "\n",
        "    # 解析关键点\n",
        "    points = []\n",
        "    for i in range(25):\n",
        "        heat_map = output[0, i, :, :]\n",
        "        _, conf, _, point = cv2.minMaxLoc(heat_map)\n",
        "        x = int((point[0] / output.shape[3]) * frame.shape[1])\n",
        "        y = int((point[1] / output.shape[2]) * frame.shape[0])\n",
        "        points.append((x, y) if conf > 0.1 else None)\n",
        "        if conf > 0.1:\n",
        "            cv2.circle(frame, (x, y), 3, (0, 255, 255), -1, cv2.LINE_AA)\n",
        "            cv2.putText(frame, f\"({x},{y})\", (x+10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)\n",
        "    cv2.line(frame, (0, frame_height // 2), (frame_width, frame_height // 2), (255, 0, 0), 2)  # 水平线\n",
        "    cv2.line(frame, (frame_width // 2, 0), (frame_width // 2, frame_height), (255, 0, 0), 2)  # 垂直线\n",
        "    all_points.append(frame_points)\n",
        "    # 绘制骨架连接线\n",
        "    for pair in pairs:\n",
        "        partA = pair[0]\n",
        "        partB = pair[1]\n",
        "        if points[partA] and points[partB]:\n",
        "            cv2.line(frame, points[partA], points[partB], (0, 255, 0), 2)\n",
        "with open('/content/keypoints.json', 'w') as f:\n",
        "    json.dump(all_points, f)\n",
        "    # 写入输出视频\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(\"视频处理完成并保存为 'output_video.mp4'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "-dq7iDpnCW08",
        "outputId": "7a60706c-67fe-4834-8611-09b2c78ba285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_points' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a74c5c99539b>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_height\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_height\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 水平线\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe_width\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe_width\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 垂直线\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mall_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# 绘制骨架连接线\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_points' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "cccf19t2j_Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFjhk2sSVRL5",
        "outputId": "0ba11a6c-0fbe-4558-ab09-1899030a5930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00f8e9a1c8862eefc073342f333391f5.mp4  openpose\t\tpose_iter_584000.caffemodel.zip\n",
            "drive\t\t\t\t      output_video.mp4\tsample_data\n"
          ]
        }
      ],
      "source": [
        "!ls /content/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyN5hNBm/MkumiIZ2iHAazJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}